# Описание проекта

В рамках задачи реализации AI-агента для интеллектуального поиска и анализа статей технологических СМИ, было разработано решение основанное на клиент-серверной архитектуре.

User-interface (клиентская часть), представлена в виде web-страницы, разработанной на React Framework с применением языка программирования typescript. Для доступа к web-странице из адресной строки браузера используется локальный web-сервер Vite. Данное решение упаковано в Docker container. Исходный код с файлом Dockerfile распологается по пути app/web. При сборке образа и запуске контейнера, открыть web-страницу можно по адресу http://localhost:5173/

Backend (серверная часть) представляет из себя python-проект, работающий на web-сервере uvcorn. За обработку http-запросов отвечание FastAPI. Решение также упаковано в Docker container. Исходный код с файлом Dockerfile располагается по пути app/backend. При сборке образа и запуске контейнера, web-сервер работает по адресу http://localhost:5151.
Основную документацию по API-интерфейсу вожно посмотреть в Swagger UI по адресу http://localhost:5151/docs/

# Локальный старт приложения
Для локального развёртывания решения. Необходимо загрузить папку app на локальную машину.
Для работы LLM-модели от Gigachat необходимо получить токен доступа и указать его в файле app/docker-compose.yml на строке 7 вместо **secret_token**:
```
1.  services:
2.    server:
3.      build:
4.        context: ./backend/
5.    network_mode: "host"
6.    environment:
7.      - GIGA_TOKEN=secret_token
8.    depends_on:
9.      - qdrant
```
После перейти в папку app и в командной строке ввести:
### MacOS

```
docker compose up
```

### linux

```
docker compose up
```
После сборки и запуска контейнеров необходимо перейти по адресу http://localhost:5173/ в адресной строке браузера.
Контейнеры можно считать запущенными при наличии в консоли следующих строк:
- Local:   http://localhost:5173/ (Запущен web-сервер Frontend)
- Uvicorn running on http://127.0.0.1:5151 (Press CTRL+C to quit) (Запущен web-сервер Backend)

Для очистки кэша docker можно использовать команду:
```
docker builder prune -f
```
# Алгоритм анализа статей
Для анализа статей был реализован функционал загрузки документов в формате PDF.
Данный документ должен соответствовать шаблону, который можно скачать на странице WEB-интерфейса.
Данный шаблон состоит из 4х частей:
- ссылка на статью (первая строка);
- автор статьи (вторая строка);
- дата публикации статьи (третья строка);
- содержимое статьи (весь остальной документ)
В случае отсутствия одного из компонентов необходимо пропустить его используя абзац.

При загрузке документа статьи через WEB-интерфейс система делит содержимое на чанки - части текста заданной длинны.
Каждый чанк проходит через унификацию текста, а именно:
- перевод всех символов в нижний регистр;
- удаление всех знаков препинания;
- удаление служебных частей речи (такие как союзы и частицы).
Обработанный текст, через BERT модель **ai-forever/ru-en-RoSBERTa** преобразуется в смысловой вектор размерностью 1024.
Полученный смысловой вектор сохраняется в специализированную векторнцю базу данных Qdrant с дополнительной информацией, такой как:
- ссылка на статью;
- автор статьи;
- дата публикации статьи;
- часть текста статьи без преобразования.
Дополнительные сведения позволяют выполнять более точный поиск и получить исходный текст для дальнейшего использования в качестве контекста LLM.

# Алгоритм подбора статей и формирования ответа пользователю
Запрос пользователя через BERT модель **ai-forever/ru-en-RoSBERTa** преобразуется в смысловой вектор размерностью 1024.
Данный вектор позволяет выполнить семантический поиск наиболее релевантных чанков в векторной базе данных Qdrant по косиноснуму сходству.
У всех найденных чанков, отсортированные по убыванию от наиболее релевантных к наименее релевантным, вытягивается информация о ссылке на статью и текстовое содержимое чанка.
Текстовое содержимое чанков собирается в контекст, размером более 1000 симв1олов.
Данный контекст с статическим промптом передается в **Giga Chat** по API-интерфейсу.
В результате получаем краткое резюме на основе релевантных чанков статей, которое отображается пользователю, а так же список ссылок на статьи которые использовались для формирования ответа. 
